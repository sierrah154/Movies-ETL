{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://en.wikipedia.org/wiki/Loveless_(film)', 'year': 2018, 'imdb_link': 'https://www.imdb.com/title/tt6304162/', 'title': 'Loveless', 'Russian': 'Нелюбовь', 'Directed by': 'Andrey Zvyagintsev', 'Produced by': ['Alexander Rodnyansky', 'Sergey Melkumov', 'Gleb Fetisov'], 'Screenplay by': ['Oleg Negin', 'Andrey Zvyagintsev'], 'Starring': ['Maryana Spivak', 'Aleksey Rozin', 'Matvey Novikov', 'Marina Vasilyeva', 'Andris Keišs'], 'Music by': ['Evgueni Galperine', 'Sacha Galperine'], 'Cinematography': 'Mikhail Krichman', 'Edited by': 'Anna Mass', 'Productioncompany ': ['Arte France Cinéma', 'Why Not Productions'], 'Distributed by': ['Sony Pictures Releasing', '(Russia)', '[1]'], 'Release date': ['18 May 2017', '(', '2017-05-18', ')', '(', 'Cannes', ')', '1 June 2017', '(', '2017-06-01', ')', '(Russia)'], 'Running time': '127 minutes', 'Country': ['Russia', 'France', 'Belgium', 'Germany', '[3]'], 'Language': 'Russian', 'Box office': '$4.8 million'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sierr\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\strings.py:710: FutureWarning: Possible set difference at position 6\n",
      "  compiled = re.compile(pat, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 69.47365832328796 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 156.01651740074158 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 340.0825991630554 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 431.12756538391113 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Done. 513.5415787696838 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Done. 591.815996170044 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Done. 662.5701503753662 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Done. 739.2025945186615 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Done. 816.3353822231293 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Done. 894.8988842964172 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Done. 971.4399111270905 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Done. 1047.8471410274506 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Done. 1124.215004682541 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Done. 1198.760048866272 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Done. 1273.7676486968994 total seconds elapsed\n",
      "importing rows 15000000 to 16000000...Done. 1377.6331896781921 total seconds elapsed\n",
      "importing rows 16000000 to 17000000...Done. 1463.1400654315948 total seconds elapsed\n",
      "importing rows 17000000 to 18000000...Done. 1540.770528793335 total seconds elapsed\n",
      "importing rows 18000000 to 19000000...Done. 1621.9596557617188 total seconds elapsed\n",
      "importing rows 19000000 to 20000000...Done. 1700.5640623569489 total seconds elapsed\n",
      "importing rows 20000000 to 21000000...Done. 1778.7373747825623 total seconds elapsed\n",
      "importing rows 21000000 to 22000000...Done. 1865.5375139713287 total seconds elapsed\n",
      "importing rows 22000000 to 23000000...Done. 1949.2919280529022 total seconds elapsed\n",
      "importing rows 23000000 to 24000000...Done. 2030.2724645137787 total seconds elapsed\n",
      "importing rows 24000000 to 25000000...Done. 2108.9618513584137 total seconds elapsed\n",
      "importing rows 25000000 to 26000000...Done. 2187.9017634391785 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Done. 2190.101188182831 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "from config import db_password\n",
    "\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) # create a non-destructive copy.\n",
    "    alt_titles = {}\n",
    "    \n",
    "    # combine alternate titles into one list.\n",
    "    for key in ['Also known as', 'Arabic', 'Cantonese', 'Chinese', 'French,'\n",
    "               'Hangul', 'Hebrew', 'Hepburn', 'Japanese', 'Literally',\n",
    "                'Mandarin', 'McCune-Reischauer', 'Original title', 'Polist',\n",
    "                'Revised Romanization', 'Romanized', 'Russian',\n",
    "                'Simplified', 'Traditional', 'Yiddish']:\n",
    "        if key in movie:\n",
    "            if key == 'Russian':\n",
    "                print(movie)\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0 :\n",
    "        movie['alt_titles'] = alt_titles\n",
    "   \n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "            \n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    \n",
    "    return movie\n",
    "\n",
    "def extract_transform_load(wiki_file, kaggle_file, ratings_file):\n",
    "\n",
    "    with open(wiki_file, mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)\n",
    "        \n",
    "    kaggle_metadata = pd.read_csv(kaggle_file, low_memory=False)\n",
    "    ratings = pd.read_csv(ratings_file)\n",
    "    \n",
    "    wiki_movies = [movie for movie in wiki_movies_raw\n",
    "                  if ('Director' in movie or 'Directed by' in movie)\n",
    "                  and 'imdb_link' in movie]\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)    \n",
    "    \n",
    "    # assuming Wikipedia data still contains IMDB id\n",
    "    try:\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "    \n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    \n",
    "    form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "    form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "    def parse_dollars(s):\n",
    "        # if s is not a string, return NaN\n",
    "        if type(s) != str:\n",
    "            return np.nan\n",
    "        # if input is of the form $###.# million\n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and \" million\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            # convert to float and multiply by a million\n",
    "            value = float(s) * 10 ** 6\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###.# billion\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and \" billion\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            # convert to float and multiply by a billion\n",
    "            value = float(s) * 10 ** 9\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###,###,###\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and commas\n",
    "            s = re.sub('\\$|,','', s)\n",
    "            # convert to float\n",
    "            value = float(s)\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # otherwise, return NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    budget = budget.str.replace(r'\\$.*[---](?![a-z])', '$', regex=True)\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "    \n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "    \n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "    \n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "    kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "    kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "    kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "    kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "    \n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "    movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "    \n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "            , axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "        \n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "    \n",
    "    movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n",
    "    \n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)\n",
    "    \n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count().rename({'userId':'count'}, axis=1).pivot(index='movieId',columns='rating', values='count')\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "    movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    \n",
    "    db_string = f\"postgres://postgres:{db_password}@localhost:5432/movie_data\"\n",
    "    engine = create_engine(db_string)\n",
    "    \n",
    "    movies_df.to_sql(name='movies', con=engine, if_exists='append')\n",
    "    \n",
    "    rows_imported = 0\n",
    "    # get the start_time from time.time()\n",
    "    start_time = time.time()\n",
    "    for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "        data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "        rows_imported += len(data)\n",
    "\n",
    "        # add elapsed time to final print out\n",
    "        print(f'Done. {time.time() - start_time} total seconds elapsed')    \n",
    "\n",
    "        \n",
    "file_dir = \"./Resources\"\n",
    "wiki_file = f'{file_dir}/wikipedia.movies.json'\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "ratings_file = f'{file_dir}/ratings.csv'\n",
    "\n",
    "extract_transform_load(wiki_file, kaggle_file, ratings_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
